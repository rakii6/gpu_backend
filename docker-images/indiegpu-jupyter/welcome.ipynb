{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üòè Welcome to IndieGPU - Your GPU powered workspace!\n",
    "\n",
    "Your container comes pre-loaded with:\n",
    "- PyTorch + CUDA\n",
    "- TensorFlow + GPU\n",
    "- Hugging Face Transformers\n",
    "- All essential ML libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Verify GPU Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"üî• PyTorch GPU Check:\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "print(\"\\nüî• TensorFlow GPU Check:\")\n",
    "print(f\"TF version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Quick GPU Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch GPU test\n",
    "if torch.cuda.is_available():\n",
    "    x = torch.randn(1000, 1000).cuda()\n",
    "    y = torch.randn(1000, 1000).cuda()\n",
    "    z = torch.mm(x, y)\n",
    "    print(\"‚úÖ PyTorch GPU computation successful!\")\n",
    "\n",
    "# TensorFlow GPU test\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    with tf.device('/GPU:0'):\n",
    "        a = tf.random.normal([1000, 1000])\n",
    "        b = tf.random.normal([1000, 1000])\n",
    "        c = tf.matmul(a, b)\n",
    "    print(\"‚úÖ TensorFlow GPU computation successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Getting Your Code In\n",
    "\n",
    "### Option A: Git Clone\n",
    "```bash\n",
    "!git clone https://github.com/yourusername/your-ml-project.git\n",
    "```\n",
    "\n",
    "### Option B: Download from Hugging Face\n",
    "```python\n",
    "from huggingface_hub import hf_hub_download\n",
    "model_path = hf_hub_download(repo_id=\"bert-base-uncased\", filename=\"pytorch_model.bin\")\n",
    "```\n",
    "\n",
    "### Option C: Download from Google Drive\n",
    "```python\n",
    "!gdown 'https://drive.google.com/uc?id=YOUR_FILE_ID'\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
